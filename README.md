# Exploring Multilingual Unseen Speaker Emotion Recognition: Leveraging Co-Attention Cues in Multitask Learning

Code Repository for the INTERSPEECH'24 Paper :
`Exploring Multilingual Unseen Speaker Emotion Recognition: Leveraging Co-Attention Cues in Multitask Learning`

The contents of this repository have been shifted to [Link](https://github.com/NLP-SBILAB/CAMuLeNet). Kindly refer to the same!

# Dataset Access:
Please fill this form for accessing the BhavVani dataset: [Form Link](https://forms.gle/9AqxS2oY4XVSeH1UA)

## Citation
If our work was found helpful, please feel free to leave a star and cite our work using:
```bibtex
@inproceedings{goel24_interspeech,
  title     = {Exploring Multilingual Unseen Speaker Emotion Recognition: Leveraging Co-Attention Cues in Multitask Learning},
  author    = {Arnav Goel and Medha Hira and Anubha Gupta},
  year      = {2024},
  booktitle = {Interspeech 2024},
  pages     = {2340--2344},
  doi       = {10.21437/Interspeech.2024-1820},
  issn      = {2958-1796},
}
```
